{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWcADJizoRPS"
      },
      "source": [
        "# YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "n5W3EufJ2Sda",
        "outputId": "9b27a73a-dce8-4c96-bc26-716fac072071"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaCHXKH22XA8"
      },
      "outputs": [],
      "source": [
        "!ln -s /content/drive/My\\ Drive/runs /content/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOyiJU8d9CbB"
      },
      "outputs": [],
      "source": [
        "!ln -s /content/drive/My\\ Drive/asl /content/asl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uTUTPGgrHZj"
      },
      "outputs": [],
      "source": [
        "!ln -s /content/drive/MyDrive/object-detection /content/object-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NEtpsP3x2dbN"
      },
      "outputs": [],
      "source": [
        "!unzip /content/object-detection/hands.v2i.yolov8.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NpPG8au910DL"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5_YXUCF2OTA"
      },
      "outputs": [],
      "source": [
        "yolo_model = YOLO('yolov10n.pt')\n",
        "results = yolo_model.train(data='/content/object-detection/data.yaml', epochs=100, imgsz=640, device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXzAe9iuhj1i"
      },
      "outputs": [],
      "source": [
        "yolo_model = YOLO('/content/runs/detect/train10/weights/best.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WdeX0IhMj31d"
      },
      "outputs": [],
      "source": [
        "yolo_model.val()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Dop7cKO7MFhG"
      },
      "outputs": [],
      "source": [
        "yolo_model.export(format='tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSv04ZPloKm4"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2lAXPmmIN7ga"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G5IfANshIvFd",
        "outputId": "06b6c195-8536-4622-9534-b3311f3d99a5"
      },
      "outputs": [],
      "source": [
        "!unzip asl.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8iamGxQtOAHB"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/asl_alphabet_train/asl_alphabet_train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HAqe6az9QQh7"
      },
      "outputs": [],
      "source": [
        "# class made for classification task -> not needed if we use YOLO\n",
        "!rm -rf '/content/asl_alphabet_train/asl_alphabet_train/nothing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6GO0EW3uP28_"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vWIrQi8IP7pU"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RTMNkd5vQAsT"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.9\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "test_size = int((len(dataset) - train_size) / 3)\n",
        "val_size = test_size * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YTXDpQykRGZV"
      },
      "outputs": [],
      "source": [
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOvzGSY2QvQY",
        "outputId": "c7bda732-865b-4bc8-c4e5-7dcde629a079"
      },
      "outputs": [],
      "source": [
        "num_train_samples = len(train_dataset)\n",
        "num_val_samples = len(val_dataset)\n",
        "num_test_samples = len(test_dataset)\n",
        "\n",
        "print(f'Number of training samples: {num_train_samples}')\n",
        "print(f'Number of validation samples: {num_val_samples}')\n",
        "print(f'Number of test samples: {num_test_samples}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPbtb-IpSDaa",
        "outputId": "c85e59c4-b66d-465f-e321-bd2d5d7043b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(dataset.classes)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BBk5pRHISI92"
      },
      "outputs": [],
      "source": [
        "#use 128 or 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e4xrr7D1JZ1d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=28):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 23 * 23, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(-1, 128 * 23 * 23)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9HXAYGWHWL78"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=0, verbose=False, path='checkpoint.pt'):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.path = path\n",
        "        self.best_model = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.verbose:\n",
        "            print(f\"Validation loss decreased ({self.best_loss:.6f} --> {val_loss:.6f}). Saving model ...\")\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.best_model = model\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, patience=10, n_epochs=100, verbose=True):\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=verbose)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Check for early stopping\n",
        "        early_stopping(val_loss, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered. Loading the best model...\")\n",
        "            model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "            break\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "cnn_model = SimpleCNN(num_classes=28).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PHSpgWtNWYF6",
        "outputId": "9fe54241-8206-4d09-bc5e-e785fa488ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Training Loss: 3.0733, Validation Loss: 2.0526\n",
            "Validation loss decreased (2.052573 --> 2.052573). Saving model ...\n",
            "Epoch 2/50, Training Loss: 2.3600, Validation Loss: 1.8489\n",
            "Validation loss decreased (2.052573 --> 1.848851). Saving model ...\n",
            "Epoch 3/50, Training Loss: 2.2153, Validation Loss: 1.5198\n",
            "Validation loss decreased (1.848851 --> 1.519756). Saving model ...\n",
            "Epoch 4/50, Training Loss: 2.1012, Validation Loss: 1.3869\n",
            "Validation loss decreased (1.519756 --> 1.386910). Saving model ...\n",
            "Epoch 5/50, Training Loss: 2.0141, Validation Loss: 1.3127\n",
            "Validation loss decreased (1.386910 --> 1.312657). Saving model ...\n",
            "Epoch 6/50, Training Loss: 1.9310, Validation Loss: 1.1645\n",
            "Validation loss decreased (1.312657 --> 1.164485). Saving model ...\n",
            "Epoch 7/50, Training Loss: 1.8645, Validation Loss: 1.1090\n",
            "Validation loss decreased (1.164485 --> 1.108969). Saving model ...\n",
            "Epoch 8/50, Training Loss: 1.7695, Validation Loss: 1.0810\n",
            "Validation loss decreased (1.108969 --> 1.081029). Saving model ...\n",
            "Epoch 9/50, Training Loss: 1.6603, Validation Loss: 0.7999\n",
            "Validation loss decreased (1.081029 --> 0.799904). Saving model ...\n",
            "Epoch 10/50, Training Loss: 1.5766, Validation Loss: 0.8757\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 11/50, Training Loss: 1.5034, Validation Loss: 0.6852\n",
            "Validation loss decreased (0.799904 --> 0.685217). Saving model ...\n",
            "Epoch 12/50, Training Loss: 1.4389, Validation Loss: 0.5854\n",
            "Validation loss decreased (0.685217 --> 0.585350). Saving model ...\n",
            "Epoch 13/50, Training Loss: 1.3572, Validation Loss: 0.5646\n",
            "Validation loss decreased (0.585350 --> 0.564566). Saving model ...\n",
            "Epoch 14/50, Training Loss: 1.2901, Validation Loss: 1.1003\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 15/50, Training Loss: 1.2463, Validation Loss: 0.4069\n",
            "Validation loss decreased (0.564566 --> 0.406939). Saving model ...\n",
            "Epoch 16/50, Training Loss: 1.2092, Validation Loss: 0.3968\n",
            "Validation loss decreased (0.406939 --> 0.396843). Saving model ...\n",
            "Epoch 17/50, Training Loss: 1.1794, Validation Loss: 0.4156\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 18/50, Training Loss: 1.1462, Validation Loss: 0.3592\n",
            "Validation loss decreased (0.396843 --> 0.359183). Saving model ...\n",
            "Epoch 19/50, Training Loss: 1.0903, Validation Loss: 0.2784\n",
            "Validation loss decreased (0.359183 --> 0.278419). Saving model ...\n",
            "Epoch 20/50, Training Loss: 1.0109, Validation Loss: 0.2550\n",
            "Validation loss decreased (0.278419 --> 0.255023). Saving model ...\n",
            "Epoch 21/50, Training Loss: 0.9629, Validation Loss: 0.1864\n",
            "Validation loss decreased (0.255023 --> 0.186449). Saving model ...\n",
            "Epoch 22/50, Training Loss: 0.9501, Validation Loss: 0.1795\n",
            "Validation loss decreased (0.186449 --> 0.179473). Saving model ...\n",
            "Epoch 23/50, Training Loss: 0.9227, Validation Loss: 0.1633\n",
            "Validation loss decreased (0.179473 --> 0.163314). Saving model ...\n",
            "Epoch 24/50, Training Loss: 0.8882, Validation Loss: 0.1806\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 25/50, Training Loss: 0.8286, Validation Loss: 0.1537\n",
            "Validation loss decreased (0.163314 --> 0.153696). Saving model ...\n",
            "Epoch 26/50, Training Loss: 0.7900, Validation Loss: 0.1578\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 27/50, Training Loss: 0.7730, Validation Loss: 0.1229\n",
            "Validation loss decreased (0.153696 --> 0.122887). Saving model ...\n",
            "Epoch 28/50, Training Loss: 0.7296, Validation Loss: 0.1158\n",
            "Validation loss decreased (0.122887 --> 0.115799). Saving model ...\n",
            "Epoch 29/50, Training Loss: 0.7039, Validation Loss: 0.1696\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 30/50, Training Loss: 0.6536, Validation Loss: 0.0768\n",
            "Validation loss decreased (0.115799 --> 0.076763). Saving model ...\n",
            "Epoch 31/50, Training Loss: 0.6303, Validation Loss: 0.0799\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 32/50, Training Loss: 0.6112, Validation Loss: 0.0789\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 33/50, Training Loss: 0.5521, Validation Loss: 0.1860\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 34/50, Training Loss: 0.4789, Validation Loss: 0.0381\n",
            "Validation loss decreased (0.076763 --> 0.038081). Saving model ...\n",
            "Epoch 35/50, Training Loss: 0.4381, Validation Loss: 0.0956\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 36/50, Training Loss: 0.4009, Validation Loss: 0.0917\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 37/50, Training Loss: 0.3767, Validation Loss: 0.0319\n",
            "Validation loss decreased (0.038081 --> 0.031940). Saving model ...\n",
            "Epoch 38/50, Training Loss: 0.3522, Validation Loss: 0.0550\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 39/50, Training Loss: 0.3099, Validation Loss: 0.4370\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 40/50, Training Loss: 0.2716, Validation Loss: 0.0174\n",
            "Validation loss decreased (0.031940 --> 0.017392). Saving model ...\n",
            "Epoch 41/50, Training Loss: 0.2354, Validation Loss: 0.0149\n",
            "Validation loss decreased (0.017392 --> 0.014919). Saving model ...\n",
            "Epoch 42/50, Training Loss: 0.2124, Validation Loss: 0.0240\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 43/50, Training Loss: 0.2029, Validation Loss: 0.0112\n",
            "Validation loss decreased (0.014919 --> 0.011191). Saving model ...\n",
            "Epoch 44/50, Training Loss: 0.1930, Validation Loss: 0.0172\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 45/50, Training Loss: 0.1833, Validation Loss: 0.0614\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 46/50, Training Loss: 0.1759, Validation Loss: 0.0208\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 47/50, Training Loss: 0.1655, Validation Loss: 0.0109\n",
            "Validation loss decreased (0.011191 --> 0.010879). Saving model ...\n",
            "Epoch 48/50, Training Loss: 0.1563, Validation Loss: 0.0118\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 49/50, Training Loss: 0.1543, Validation Loss: 0.0072\n",
            "Validation loss decreased (0.010879 --> 0.007208). Saving model ...\n",
            "Epoch 50/50, Training Loss: 0.1483, Validation Loss: 0.0083\n",
            "EarlyStopping counter: 1 out of 5\n"
          ]
        }
      ],
      "source": [
        "train_model(cnn_model, train_loader, val_loader, criterion, optimizer, patience=5, n_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ryQpEex9x2Di",
        "outputId": "826d2da8-6181-4f6d-f862-446776c5020b"
      },
      "outputs": [],
      "source": [
        "cnn_model = SimpleCNN(num_classes=28)\n",
        "cnn_model.load_state_dict(torch.load('checkpoint.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Exy5jmLNdhPD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    return acc, prec, rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZzLRRBEDdtSa",
        "outputId": "81b397ad-50c1-4f09-f076-389bf54eb8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0034\n",
            "Accuracy: 0.9996, Precision: 0.9996, Recall: 0.9996\n"
          ]
        }
      ],
      "source": [
        "def test_model(model, test_loader, criterion, device='cpu'):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "\n",
        "    accuracy, precision, recall = calculate_metrics(y_true, y_pred)\n",
        "\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "\n",
        "cnn_model.to(device)\n",
        "test_model(cnn_model, test_loader, criterion, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN2JOz1_psfK"
      },
      "source": [
        "# Conversion from Pytorch to tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "aIaC9-H84tE1",
        "outputId": "e127a3f7-d4ba-4aee-a201-29803f9e1c70"
      },
      "outputs": [],
      "source": [
        "!pip install ai-edge-torch-nightly torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b0jmowz48-D",
        "outputId": "32f9331c-afcc-4df0-ddda-201fc3675d9f"
      },
      "outputs": [],
      "source": [
        "import ai_edge_torch\n",
        "import numpy\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "cnn_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f36xHPLy25Cb"
      },
      "outputs": [],
      "source": [
        "sample_inputs = (torch.randn(1, 3, 200, 200),)\n",
        "edge_model = ai_edge_torch.convert(cnn_model, sample_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyj6NWa7qL-d"
      },
      "outputs": [],
      "source": [
        "edge_model.export('cnn_model.tflite')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
